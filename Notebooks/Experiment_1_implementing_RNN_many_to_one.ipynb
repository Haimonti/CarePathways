{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6ba83a5",
   "metadata": {},
   "source": [
    "### Implementing RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4592fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppress a specific warning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fcfdfc",
   "metadata": {},
   "source": [
    "### Initially we will calculate the days remaining in the hospital which is given by the hospital length of stay - the day in the hospital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9508f88b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_id</th>\n",
       "      <th>systolic_blood_pressure</th>\n",
       "      <th>diastolic_blood_pressure</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>respiratory_rate</th>\n",
       "      <th>oxygen_saturation</th>\n",
       "      <th>temperature</th>\n",
       "      <th>highest_mean_arterial_pressure</th>\n",
       "      <th>lowest_mean_arterial_pressure</th>\n",
       "      <th>highest_heart_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>Bilateral Ground Glass</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Unilateral Consolidation</th>\n",
       "      <th>Bilateral Ground Glass Opacities</th>\n",
       "      <th>Bilateral consolidationinfiltration</th>\n",
       "      <th>Pulmonary Embolism</th>\n",
       "      <th>Scarring or Fibrosis</th>\n",
       "      <th>days_remaining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>92.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>97.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>71.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>140.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>108.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>126.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>511</td>\n",
       "      <td>150.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>511</td>\n",
       "      <td>116.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>36.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>511</td>\n",
       "      <td>131.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>511</td>\n",
       "      <td>129.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>36.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>511</td>\n",
       "      <td>126.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>784 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     parent_id  systolic_blood_pressure  diastolic_blood_pressure  heart_rate  \\\n",
       "0            6                    127.0                      76.0        68.0   \n",
       "1            6                     97.0                      60.0        68.0   \n",
       "2            6                    140.0                      68.0        72.0   \n",
       "3            6                    108.0                      63.0        98.0   \n",
       "4            6                    126.0                      77.0        68.0   \n",
       "..         ...                      ...                       ...         ...   \n",
       "779        511                    150.0                      50.0        67.0   \n",
       "780        511                    116.0                      54.0        57.0   \n",
       "781        511                    131.0                      74.0        53.0   \n",
       "782        511                    129.0                      58.0        57.0   \n",
       "783        511                    126.0                      53.0        78.0   \n",
       "\n",
       "     respiratory_rate  oxygen_saturation  temperature  \\\n",
       "0                19.0               95.0         36.6   \n",
       "1                22.0               98.0         36.4   \n",
       "2                22.0               99.0         36.5   \n",
       "3                22.0               95.0         36.5   \n",
       "4                24.0               98.0         36.5   \n",
       "..                ...                ...          ...   \n",
       "779              27.0               93.0         36.8   \n",
       "780              21.0               97.0         36.9   \n",
       "781              22.0               92.0         36.4   \n",
       "782              40.0               96.0         36.9   \n",
       "783              18.0               96.0         36.4   \n",
       "\n",
       "     highest_mean_arterial_pressure  lowest_mean_arterial_pressure  \\\n",
       "0                              92.0                           80.0   \n",
       "1                              71.0                           67.0   \n",
       "2                              84.0                           84.0   \n",
       "3                              77.0                           77.0   \n",
       "4                              92.0                           92.0   \n",
       "..                              ...                            ...   \n",
       "779                             0.0                            0.0   \n",
       "780                             0.0                            0.0   \n",
       "781                             0.0                            0.0   \n",
       "782                             0.0                            0.0   \n",
       "783                             0.0                            0.0   \n",
       "\n",
       "     highest_heart_rate  ...  Bilateral Ground Glass  Cardiomegaly  Edema  \\\n",
       "0                  77.0  ...                       0             0      0   \n",
       "1                  77.0  ...                       0             0      0   \n",
       "2                  97.0  ...                       0             0      0   \n",
       "3                 107.0  ...                       0             0      0   \n",
       "4                  77.0  ...                       0             0      0   \n",
       "..                  ...  ...                     ...           ...    ...   \n",
       "779                86.0  ...                       0             0      0   \n",
       "780                64.0  ...                       0             0      0   \n",
       "781                79.0  ...                       0             0      0   \n",
       "782                96.0  ...                       0             0      0   \n",
       "783               100.0  ...                       0             0      0   \n",
       "\n",
       "     Effusion  Unilateral Consolidation  Bilateral Ground Glass Opacities  \\\n",
       "0           0                         0                                 0   \n",
       "1           0                         0                                 0   \n",
       "2           0                         0                                 0   \n",
       "3           1                         0                                 0   \n",
       "4           0                         0                                 1   \n",
       "..        ...                       ...                               ...   \n",
       "779         0                         0                                 0   \n",
       "780         0                         0                                 0   \n",
       "781         0                         0                                 0   \n",
       "782         0                         0                                 0   \n",
       "783         0                         0                                 0   \n",
       "\n",
       "     Bilateral consolidationinfiltration  Pulmonary Embolism  \\\n",
       "0                                      0                   0   \n",
       "1                                      0                   0   \n",
       "2                                      0                   0   \n",
       "3                                      0                   0   \n",
       "4                                      1                   0   \n",
       "..                                   ...                 ...   \n",
       "779                                    0                   0   \n",
       "780                                    0                   0   \n",
       "781                                    0                   0   \n",
       "782                                    0                   0   \n",
       "783                                    0                   0   \n",
       "\n",
       "     Scarring or Fibrosis  days_remaining  \n",
       "0                       0              31  \n",
       "1                       0              30  \n",
       "2                       0              29  \n",
       "3                       0              28  \n",
       "4                       0              27  \n",
       "..                    ...             ...  \n",
       "779                     0              14  \n",
       "780                     0              13  \n",
       "781                     0              12  \n",
       "782                     0              11  \n",
       "783                     0               4  \n",
       "\n",
       "[784 rows x 67 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Datasets/df_over_14.csv\")\n",
    "df = df.drop(['Unnamed: 0'],axis=1)\n",
    "df['days_remaining'] = df['hospital_length_of_stay']-df['day']\n",
    "df = df.drop(['hospital_length_of_stay','day'],axis=1)\n",
    "\n",
    "# List of binary columns\n",
    "columns_binary = [\n",
    "    'intubated', 'cardiac_arrest', 'arrested_time', 'major_cardiac_events', \n",
    "    'clinically_diagnosed_infections', 'mechanical_ventilation', 'antiarrhythmic_therapies', \n",
    "    'renal_replacement_therapy_dialysis', 'cardiovascular_mechanical_support', 'echocardiogram', \n",
    "    'chest_x_ray', 'chest_ct', 'head_ct', 'antimicrobial', 'anticoagulation', 'steroid',\n",
    "    'Bilateral Consolidation', 'Bilateral Ground Glass', 'Cardiomegaly', 'Edema', 'Effusion', \n",
    "    'Pneumothorax', 'Unilateral Consolidation', 'Unilateral Ground Glass', 'Bilateral Ground Glass Opacities',\n",
    "    'Bilateral consolidationinfiltration', 'Subarachnoid Hemorrhage', 'Subdural Hemorrhage',\n",
    "    'Emphysematous or Bronchiectasis changes', 'Emphysematous or Bronchiectatic changes', \n",
    "    'Pulmonary Embolism', 'Scarring or Fibrosis', 'Unilateral Ground Glass Opacities', \n",
    "    'Unilateral consolidationinfiltration'\n",
    "]\n",
    "\n",
    "# Define columns to exclude from scaling\n",
    "columns_to_exclude = ['parent_id', 'days_remaining'] + columns_binary\n",
    "\n",
    "# Select the columns to scale\n",
    "columns_to_scale = [col for col in df.columns if col not in columns_to_exclude]\n",
    "\n",
    "## Removing columns having days remaining less than 0\n",
    "df = df[df['days_remaining']>0]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b533d7a",
   "metadata": {},
   "source": [
    "### Define a simple RNN model and other resuable functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2d8352ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# This line defines a class SimpleRNN that inherits from torch.nn.Module. \n",
    "#In PyTorch, the Module class is the base class for all neural network modules,\n",
    "#and it provides essential functions for building and training models.\n",
    "class SimpleRNN(nn.Module):\n",
    "    ## constructor that initiaes once the class SimpleRNN is called\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        ## this is an RNN layer that takes inputsize, hiddensize\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        ## this is a fully connected layer which will give us the output\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "   ## this is the way in which our RNN will operate in forward\n",
    "    def forward(self, x):\n",
    "        ## first the input values will be sent to the RNN\n",
    "        ## it will give out two values out: This is the output of the RNN layer. \n",
    "            # It contains the hidden states of the RNN at all time steps.\n",
    "        ##_: The second value returned by self.rnn(x) is the hidden state for the next time step\n",
    "            #(which is usually not needed in a basic RNN setup like this, so we use _ to ignore it).\n",
    "        out, _ = self.rnn(x)\n",
    "        ## the out consists of the output from each of the timestamp \n",
    "        ## which is also the hidden layer for the next timestamp\n",
    "        ## out[:, -1, :] gives the ouptut of the last layer \n",
    "        ## which is also the hidden layer of the next timestamp\n",
    "        ## but in this case it will only be used to produce the output\n",
    "        ## _ in the above gives the hidden state produced at timestamp t for the next timestamp (t+1)\n",
    "        ## it is not used so discarded\n",
    "        ## out[:,-1,:] and _ will give the same output\n",
    "        out = out[:, -1, :] \n",
    "        ## below we will pass the output of the last timestep and pass to a fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "# Define the data extraction function (many-to-many)\n",
    "def get_data_for_parent(df, parent_id):\n",
    "    data = df[df['parent_id'] == parent_id]\n",
    "    features = data.drop(columns=['parent_id', 'days_remaining'])\n",
    "    target = data['days_remaining'].values\n",
    "    \n",
    "    # Convert to tensors\n",
    "    features_tensor = torch.tensor(features.values).float().unsqueeze(0)  # Add batch dimension\n",
    "    target_tensor = torch.tensor(target).float().unsqueeze(0)  # Add batch dimension\n",
    "    return features_tensor, target_tensor\n",
    "\n",
    "# Define the ensemble prediction function\n",
    "def ensemble_prediction(models, input_data):\n",
    "    predictions = []\n",
    "    \n",
    "    # Get predictions from each model\n",
    "    for model in models:\n",
    "        model.eval()  # Switch to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            output = model(input_data)\n",
    "            predictions.append(output.squeeze().tolist())  # Store the predictions for each timestep\n",
    "        \n",
    "    # Average the predictions to form the final prediction at each timestep\n",
    "    return torch.mean(torch.tensor(predictions), dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa7331e",
   "metadata": {},
   "source": [
    "###  Using minmax scaler to scale the data and doing a train test split as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "211525c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in the dataset: 784\n",
      "Train dataset rows: 584\n",
      "Test dataset rows: 200\n",
      "Parent ID: 14, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 15, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 25, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 40, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 41, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 50, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 51, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 61, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 74, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 80, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 82, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 88, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 91, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 99, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 103, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 105, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 113, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 123, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 124, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 144, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 150, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 166, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 168, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 179, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 199, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 211, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 215, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 218, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 234, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 238, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 256, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 265, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 277, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 281, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 289, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 302, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 310, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 312, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 315, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 316, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 317, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 320, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 321, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 326, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 332, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 340, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 346, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 348, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 360, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 362, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 366, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 371, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 376, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 377, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 387, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 392, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 393, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 395, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 404, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 406, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 412, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 425, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 430, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 433, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 434, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 437, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 445, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 458, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 460, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 464, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 481, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 486, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 511, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform only the columns that need scaling\n",
    "df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
    "\n",
    "# Step 2: Split based on unique parent_id\n",
    "unique_parent_ids = df['parent_id'].unique()\n",
    "\n",
    "# Randomly shuffle and split into 75% train and 25% test\n",
    "train_parent_ids, test_parent_ids = train_test_split(unique_parent_ids, test_size=0.25, random_state=42)\n",
    "\n",
    "# Filter the dataset based on the split\n",
    "train_df = df[df['parent_id'].isin(train_parent_ids)]\n",
    "test_df = df[df['parent_id'].isin(test_parent_ids)]\n",
    "\n",
    "# Display the results\n",
    "print(f\"Total rows in the dataset: {len(df)}\")\n",
    "print(f\"Train dataset rows: {len(train_df)}\")\n",
    "print(f\"Test dataset rows: {len(test_df)}\")\n",
    "\n",
    "# Example: Pass 75% (train_df) to the next function\n",
    "for parent_id in train_df['parent_id'].unique():\n",
    "    features, target = get_data_for_parent(train_df, parent_id)\n",
    "    # Example: Print the features and target shapes\n",
    "    print(f\"Parent ID: {parent_id}, Features Shape: {features.shape}, Target Shape: {target.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e76f5bf",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "641a4419",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m overall_models \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      9\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModels\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(output_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     12\u001b[0m input_size \u001b[38;5;241m=\u001b[39m train_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparent_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdays_remaining\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     13\u001b[0m output_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Single output for each timestep\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning configuration\n",
    "tuning_params = {\n",
    "    'hidden_size': [32, 64],\n",
    "    'learning_rate': [0.001, 0.005],\n",
    "    'num_epochs': [500, 1000]\n",
    "}\n",
    "best_mse = float('inf')\n",
    "best_params = None\n",
    "models = []\n",
    "\n",
    "# Training loop with hyperparameter tuning\n",
    "input_size = train_df.drop(columns=['parent_id', 'days_remaining']).shape[1]\n",
    "output_size = 1  # Single output for each timestep\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "output_dir = \"Models\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "start_time = time.time()\n",
    "\n",
    "for hidden_size in tuning_params['hidden_size']:\n",
    "    for learning_rate in tuning_params['learning_rate']:\n",
    "        for num_epochs in tuning_params['num_epochs']:\n",
    "            print(f\"Training with hidden_size={hidden_size}, learning_rate={learning_rate}, num_epochs={num_epochs}...\")\n",
    "            fold_models = []\n",
    "            mse_list = []\n",
    "            \n",
    "            for parent_id in train_df['parent_id'].unique():\n",
    "                # Data for current parent_id\n",
    "                features, target = get_data_for_parent(train_df, parent_id)\n",
    "\n",
    "                # Initialize model\n",
    "                model = SimpleRNN(input_size, hidden_size, output_size)\n",
    "                optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "                # Training\n",
    "                model.train()\n",
    "                for epoch in range(num_epochs):\n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(features)\n",
    "                    loss = criterion(output, target)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Save model and record loss\n",
    "                fold_models.append(model)\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    predictions = model(features)\n",
    "                    mse = criterion(predictions, target).item()\n",
    "                    mse_list.append(mse)\n",
    "\n",
    "            # Compute mean MSE for this parameter configuration\n",
    "            mean_mse = np.mean(mse_list)\n",
    "            print(f\"Mean MSE for configuration: {mean_mse}\")\n",
    "\n",
    "            # Save the best configuration\n",
    "            if mean_mse < best_mse:\n",
    "                best_mse = mean_mse\n",
    "                best_params = {'hidden_size': hidden_size, 'learning_rate': learning_rate, 'num_epochs': num_epochs}\n",
    "                models = fold_models\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Total training time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b5b069d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=500...\n",
      "Training completed in 24.88 seconds.\n",
      "Best Model MSE on test data: 328.0070569380498\n"
     ]
    }
   ],
   "source": [
    "# Training function\n",
    "def train_rnn(train_df, input_size, hidden_size, output_size, learning_rate, num_epochs):\n",
    "    models = []\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Train a model for each unique parent_id\n",
    "    for parent_id in train_df['parent_id'].unique():\n",
    "        features, target = get_data_for_parent(train_df, parent_id)\n",
    "\n",
    "        # Initialize model\n",
    "        model = SimpleRNN(input_size, hidden_size, output_size)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        for epoch in range(num_epochs):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(features)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "# Evaluate the model on test data\n",
    "def evaluate_rnn(models, test_df):\n",
    "    X_test = test_df.drop(columns=['parent_id', 'days_remaining'])\n",
    "    y_test = test_df['days_remaining']\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "    for i in range(len(X_test)):\n",
    "        test_sample = torch.tensor(X_test.iloc[i].values).float().unsqueeze(0).unsqueeze(0)\n",
    "        true_value = y_test.iloc[i]\n",
    "        prediction = ensemble_prediction(models, test_sample)\n",
    "        y_true.append(true_value)\n",
    "        y_pred.append(prediction)\n",
    "\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return mse, y_true, y_pred\n",
    "\n",
    "# Set hyperparameters\n",
    "hidden_size = 64\n",
    "learning_rate =0.005\n",
    "num_epochs = 1000\n",
    "\n",
    "# Prepare input size and output size\n",
    "input_size = train_df.drop(columns=['parent_id', 'days_remaining']).shape[1]\n",
    "output_size = 1\n",
    "\n",
    "# Train the RNN with the best hyperparameters\n",
    "print(f\"Training with hidden_size={hidden_size}, learning_rate={learning_rate}, num_epochs={num_epochs}...\")\n",
    "start_time = time.time()\n",
    "models = train_rnn(train_df, input_size, hidden_size, output_size, learning_rate, num_epochs)\n",
    "end_time = time.time()\n",
    "print(f\"Training completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "# Evaluate on test data\n",
    "mse, y_true, y_pred = evaluate_rnn(models, test_df)\n",
    "print(f\"Best Model MSE on test data: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a728ddf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
