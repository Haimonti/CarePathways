{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db37ac26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppress a specific warning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "748d2d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_id</th>\n",
       "      <th>systolic_blood_pressure</th>\n",
       "      <th>diastolic_blood_pressure</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>respiratory_rate</th>\n",
       "      <th>oxygen_saturation</th>\n",
       "      <th>temperature</th>\n",
       "      <th>highest_mean_arterial_pressure</th>\n",
       "      <th>lowest_mean_arterial_pressure</th>\n",
       "      <th>highest_heart_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>Bilateral Ground Glass</th>\n",
       "      <th>Cardiomegaly</th>\n",
       "      <th>Edema</th>\n",
       "      <th>Effusion</th>\n",
       "      <th>Unilateral Consolidation</th>\n",
       "      <th>Bilateral Ground Glass Opacities</th>\n",
       "      <th>Bilateral consolidationinfiltration</th>\n",
       "      <th>Pulmonary Embolism</th>\n",
       "      <th>Scarring or Fibrosis</th>\n",
       "      <th>days_remaining</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>36.6</td>\n",
       "      <td>92.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>97.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>71.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>140.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>108.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>126.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>36.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>511</td>\n",
       "      <td>150.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>511</td>\n",
       "      <td>116.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>36.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>511</td>\n",
       "      <td>131.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>511</td>\n",
       "      <td>129.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>36.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>511</td>\n",
       "      <td>126.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>784 rows Ã— 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     parent_id  systolic_blood_pressure  diastolic_blood_pressure  heart_rate  \\\n",
       "0            6                    127.0                      76.0        68.0   \n",
       "1            6                     97.0                      60.0        68.0   \n",
       "2            6                    140.0                      68.0        72.0   \n",
       "3            6                    108.0                      63.0        98.0   \n",
       "4            6                    126.0                      77.0        68.0   \n",
       "..         ...                      ...                       ...         ...   \n",
       "779        511                    150.0                      50.0        67.0   \n",
       "780        511                    116.0                      54.0        57.0   \n",
       "781        511                    131.0                      74.0        53.0   \n",
       "782        511                    129.0                      58.0        57.0   \n",
       "783        511                    126.0                      53.0        78.0   \n",
       "\n",
       "     respiratory_rate  oxygen_saturation  temperature  \\\n",
       "0                19.0               95.0         36.6   \n",
       "1                22.0               98.0         36.4   \n",
       "2                22.0               99.0         36.5   \n",
       "3                22.0               95.0         36.5   \n",
       "4                24.0               98.0         36.5   \n",
       "..                ...                ...          ...   \n",
       "779              27.0               93.0         36.8   \n",
       "780              21.0               97.0         36.9   \n",
       "781              22.0               92.0         36.4   \n",
       "782              40.0               96.0         36.9   \n",
       "783              18.0               96.0         36.4   \n",
       "\n",
       "     highest_mean_arterial_pressure  lowest_mean_arterial_pressure  \\\n",
       "0                              92.0                           80.0   \n",
       "1                              71.0                           67.0   \n",
       "2                              84.0                           84.0   \n",
       "3                              77.0                           77.0   \n",
       "4                              92.0                           92.0   \n",
       "..                              ...                            ...   \n",
       "779                             0.0                            0.0   \n",
       "780                             0.0                            0.0   \n",
       "781                             0.0                            0.0   \n",
       "782                             0.0                            0.0   \n",
       "783                             0.0                            0.0   \n",
       "\n",
       "     highest_heart_rate  ...  Bilateral Ground Glass  Cardiomegaly  Edema  \\\n",
       "0                  77.0  ...                       0             0      0   \n",
       "1                  77.0  ...                       0             0      0   \n",
       "2                  97.0  ...                       0             0      0   \n",
       "3                 107.0  ...                       0             0      0   \n",
       "4                  77.0  ...                       0             0      0   \n",
       "..                  ...  ...                     ...           ...    ...   \n",
       "779                86.0  ...                       0             0      0   \n",
       "780                64.0  ...                       0             0      0   \n",
       "781                79.0  ...                       0             0      0   \n",
       "782                96.0  ...                       0             0      0   \n",
       "783               100.0  ...                       0             0      0   \n",
       "\n",
       "     Effusion  Unilateral Consolidation  Bilateral Ground Glass Opacities  \\\n",
       "0           0                         0                                 0   \n",
       "1           0                         0                                 0   \n",
       "2           0                         0                                 0   \n",
       "3           1                         0                                 0   \n",
       "4           0                         0                                 1   \n",
       "..        ...                       ...                               ...   \n",
       "779         0                         0                                 0   \n",
       "780         0                         0                                 0   \n",
       "781         0                         0                                 0   \n",
       "782         0                         0                                 0   \n",
       "783         0                         0                                 0   \n",
       "\n",
       "     Bilateral consolidationinfiltration  Pulmonary Embolism  \\\n",
       "0                                      0                   0   \n",
       "1                                      0                   0   \n",
       "2                                      0                   0   \n",
       "3                                      0                   0   \n",
       "4                                      1                   0   \n",
       "..                                   ...                 ...   \n",
       "779                                    0                   0   \n",
       "780                                    0                   0   \n",
       "781                                    0                   0   \n",
       "782                                    0                   0   \n",
       "783                                    0                   0   \n",
       "\n",
       "     Scarring or Fibrosis  days_remaining  \n",
       "0                       0              31  \n",
       "1                       0              30  \n",
       "2                       0              29  \n",
       "3                       0              28  \n",
       "4                       0              27  \n",
       "..                    ...             ...  \n",
       "779                     0              14  \n",
       "780                     0              13  \n",
       "781                     0              12  \n",
       "782                     0              11  \n",
       "783                     0               4  \n",
       "\n",
       "[784 rows x 67 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Datasets/df_over_14.csv\")\n",
    "df = df.drop(['Unnamed: 0'],axis=1)\n",
    "df['days_remaining'] = df['hospital_length_of_stay']-df['day']\n",
    "df = df.drop(['hospital_length_of_stay','day'],axis=1)\n",
    "\n",
    "# List of binary columns\n",
    "columns_binary = [\n",
    "    'intubated', 'cardiac_arrest', 'arrested_time', 'major_cardiac_events', \n",
    "    'clinically_diagnosed_infections', 'mechanical_ventilation', 'antiarrhythmic_therapies', \n",
    "    'renal_replacement_therapy_dialysis', 'cardiovascular_mechanical_support', 'echocardiogram', \n",
    "    'chest_x_ray', 'chest_ct', 'head_ct', 'antimicrobial', 'anticoagulation', 'steroid',\n",
    "    'Bilateral Consolidation', 'Bilateral Ground Glass', 'Cardiomegaly', 'Edema', 'Effusion', \n",
    "    'Pneumothorax', 'Unilateral Consolidation', 'Unilateral Ground Glass', 'Bilateral Ground Glass Opacities',\n",
    "    'Bilateral consolidationinfiltration', 'Subarachnoid Hemorrhage', 'Subdural Hemorrhage',\n",
    "    'Emphysematous or Bronchiectasis changes', 'Emphysematous or Bronchiectatic changes', \n",
    "    'Pulmonary Embolism', 'Scarring or Fibrosis', 'Unilateral Ground Glass Opacities', \n",
    "    'Unilateral consolidationinfiltration'\n",
    "]\n",
    "\n",
    "# Define columns to exclude from scaling\n",
    "columns_to_exclude = ['parent_id', 'days_remaining'] + columns_binary\n",
    "\n",
    "# Select the columns to scale\n",
    "columns_to_scale = [col for col in df.columns if col not in columns_to_exclude]\n",
    "\n",
    "## Removing columns having days remaining less than 0\n",
    "df = df[df['days_remaining']>0]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14034bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# This line defines a class SimpleRNN that inherits from torch.nn.Module. \n",
    "#In PyTorch, the Module class is the base class for all neural network modules,\n",
    "#and it provides essential functions for building and training models.\n",
    "class SimpleRNN(nn.Module):\n",
    "    ## constructor that initiaes once the class SimpleRNN is called\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        ## this is an RNN layer that takes inputsize, hiddensize\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        ## this is a fully connected layer which will give us the output\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "   ## this is the way in which our RNN will operate in forward\n",
    "    def forward(self, x):\n",
    "        ## first the input values will be sent to the RNN\n",
    "        ## it will give out two values out: This is the output of the RNN layer. \n",
    "            # It contains the hidden states of the RNN at all time steps.\n",
    "        ##_: The second value returned by self.rnn(x) is the hidden state for the next time step\n",
    "            #(which is usually not needed in a basic RNN setup like this, so we use _ to ignore it).\n",
    "        out, _ = self.rnn(x)\n",
    "        ## the out consists of the output from each of the timestamp \n",
    "        ## which is also the hidden layer for the next timestamp\n",
    "        ## out[:, -1, :] gives the ouptut of the last layer \n",
    "        ## which is also the hidden layer of the next timestamp\n",
    "        ## but in this case it will only be used to produce the output\n",
    "        ## _ in the above gives the hidden state produced at timestamp t for the next timestamp (t+1)\n",
    "        ## it is not used so discarded\n",
    "        ## out[:,-1,:] and _ will give the same output\n",
    "        out = out[:, -1, :] \n",
    "        ## below we will pass the output of the last timestep and pass to a fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "# Define the data extraction function (many-to-many)\n",
    "def get_data_for_parent(df, parent_id):\n",
    "    data = df[df['parent_id'] == parent_id]\n",
    "    features = data.drop(columns=['parent_id', 'days_remaining'])\n",
    "    target = data['days_remaining'].values\n",
    "    \n",
    "    # Convert to tensors\n",
    "    features_tensor = torch.tensor(features.values).float().unsqueeze(0)  # Add batch dimension\n",
    "    target_tensor = torch.tensor(target).float().unsqueeze(0)  # Add batch dimension\n",
    "    return features_tensor, target_tensor\n",
    "\n",
    "# Define the ensemble prediction function\n",
    "def ensemble_prediction(models, input_data):\n",
    "    predictions = []\n",
    "    \n",
    "    # Get predictions from each model\n",
    "    for model in models:\n",
    "        model.eval()  # Switch to evaluation mode\n",
    "        with torch.no_grad():\n",
    "            output = model(input_data)\n",
    "            predictions.append(output.squeeze().tolist())  # Store the predictions for each timestep\n",
    "        \n",
    "    # Average the predictions to form the final prediction at each timestep\n",
    "    return torch.mean(torch.tensor(predictions), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4216b8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in the dataset: 784\n",
      "Train dataset rows: 584\n",
      "Validation dataset rows: 120\n",
      "Test dataset rows: 200\n",
      "Parent ID: 40, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 51, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 144, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 199, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 215, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 234, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 256, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 277, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 310, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 320, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 360, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 395, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 433, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 445, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n",
      "Parent ID: 464, Features Shape: torch.Size([1, 8, 65]), Target Shape: torch.Size([1, 8])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform only the columns that need scaling\n",
    "df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])\n",
    "\n",
    "# Step 2: Split based on unique parent_id\n",
    "unique_parent_ids = df['parent_id'].unique()\n",
    "\n",
    "# Randomly shuffle and split into 75% train and 25% test\n",
    "train_parent_ids, test_parent_ids = train_test_split(unique_parent_ids, test_size=0.25, random_state=42)\n",
    "\n",
    "# Further split train_parent_ids into training (80%) and validation (20%)\n",
    "train_parent_ids_new, val_parent_ids = train_test_split(train_parent_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "# Filter the dataset based on the split\n",
    "train_df = df[df['parent_id'].isin(train_parent_ids)]\n",
    "val_df = df[df['parent_id'].isin(val_parent_ids)]\n",
    "test_df = df[df['parent_id'].isin(test_parent_ids)]\n",
    "\n",
    "# Display the results\n",
    "print(f\"Total rows in the dataset: {len(df)}\")\n",
    "print(f\"Train dataset rows: {len(train_df)}\")\n",
    "print(f\"Validation dataset rows: {len(val_df)}\")\n",
    "print(f\"Test dataset rows: {len(test_df)}\")\n",
    "\n",
    "# Example: Pass train_df to the next function\n",
    "for parent_id in val_df['parent_id'].unique():\n",
    "    features, target = get_data_for_parent(val_df, parent_id)\n",
    "    # Example: Print the features and target shapes\n",
    "    print(f\"Parent ID: {parent_id}, Features Shape: {features.shape}, Target Shape: {target.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5f37938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning for Patient ID: 40\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=500: 16.360858917236328\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=1000: 14.439355850219727\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=500: 14.4375\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=500: 14.437527656555176\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=1000: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=500: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Tuning for Patient ID: 51\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=500: 14.726346015930176\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=1000: 14.43750286102295\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=500: 14.4375\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=500: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=1000: 14.437500953674316\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=500: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Tuning for Patient ID: 144\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=500: 14.458738327026367\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=1000: 14.437500953674316\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=500: 14.4375\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=500: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=1000: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=500: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Tuning for Patient ID: 199\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=500: 21.873491287231445\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=1000: 14.464884757995605\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=500: 14.4375\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=500: 14.450847625732422\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=1000: 14.437499046325684\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=500: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Tuning for Patient ID: 215\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=500: 28.33727264404297\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=1000: 14.498701095581055\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=500: 14.437499046325684\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=1000: 14.437500953674316\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=500: 14.479162216186523\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=1000: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=500: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Tuning for Patient ID: 234\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=500: 306.9064025878906\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=1000: 76.67430114746094\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=500: 14.461633682250977\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=500: 70.96866607666016\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=1000: 14.721223831176758\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=500: 14.437500953674316\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Tuning for Patient ID: 256\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=500: 14.439905166625977\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=1000: 14.4375\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=500: 14.4375\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=500...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=500: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=1000: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=500: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Tuning for Patient ID: 277\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=500: 64.5365982055664\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=1000: 16.603971481323242\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=500: 14.437499046325684\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=500: 16.246456146240234\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=1000: 14.437506675720215\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=500: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=1000: 14.437499046325684\n",
      "Tuning for Patient ID: 310\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=500: 1293.9090576171875\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=1000: 569.1893310546875\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=500: 29.592723846435547\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=1000: 14.438053131103516\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=500: 498.3398132324219\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=1000: 63.360572814941406\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=500: 14.437643051147461\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Tuning for Patient ID: 320\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=500: 655.1143188476562\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=1000: 218.08653259277344\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=500: 15.427797317504883\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=500: 196.88113403320312\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=1000: 20.10323143005371\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=500: 14.437499046325684\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=1000: 14.437499046325684\n",
      "Tuning for Patient ID: 360\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=500: 46.62755584716797\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=1000: 15.095993041992188\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=500: 14.437499046325684\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=1000: 14.437499046325684\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=500: 14.901556015014648\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=1000: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=500: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Tuning for Patient ID: 395\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=500: 14.438854217529297\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=1000: 14.4375\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=500: 14.4375\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=500: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=1000: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=500: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Tuning for Patient ID: 433\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=500: 59.63591766357422\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=1000: 15.502326965332031\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=500: 14.4375\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=1000: 14.437500953674316\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=500: 15.155826568603516\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=1000: 14.437501907348633\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=500: 14.437499046325684\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=1000: 14.437499046325684\n",
      "Tuning for Patient ID: 445\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=500...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=500: 26.653030395507812\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=1000: 14.500055313110352\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=500: 14.437499046325684\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=500: 14.467806816101074\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=1000: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=500: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Tuning for Patient ID: 464\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=500: 145.13888549804688\n",
      "Training with hidden_size=32, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.001, num_epochs=1000: 26.132661819458008\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=500: 14.43752670288086\n",
      "Training with hidden_size=32, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=32, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=500: 24.97736167907715\n",
      "Training with hidden_size=64, learning_rate=0.001, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.001, num_epochs=1000: 14.443061828613281\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=500...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=500: 14.437499046325684\n",
      "Training with hidden_size=64, learning_rate=0.005, num_epochs=1000...\n",
      "Validation MSE for hidden_size=64, learning_rate=0.005, num_epochs=1000: 14.4375\n",
      "Total training time: 53.64 seconds\n",
      "Best Model for Patient ID 40 with Params: {'hidden_size': 32, 'learning_rate': 0.005, 'num_epochs': 500}, MSE: 14.4375\n",
      "Best Model for Patient ID 51 with Params: {'hidden_size': 32, 'learning_rate': 0.005, 'num_epochs': 500}, MSE: 14.4375\n",
      "Best Model for Patient ID 144 with Params: {'hidden_size': 32, 'learning_rate': 0.005, 'num_epochs': 500}, MSE: 14.4375\n",
      "Best Model for Patient ID 199 with Params: {'hidden_size': 64, 'learning_rate': 0.001, 'num_epochs': 1000}, MSE: 14.437499046325684\n",
      "Best Model for Patient ID 215 with Params: {'hidden_size': 32, 'learning_rate': 0.005, 'num_epochs': 500}, MSE: 14.437499046325684\n",
      "Best Model for Patient ID 234 with Params: {'hidden_size': 32, 'learning_rate': 0.005, 'num_epochs': 1000}, MSE: 14.4375\n",
      "Best Model for Patient ID 256 with Params: {'hidden_size': 32, 'learning_rate': 0.001, 'num_epochs': 1000}, MSE: 14.4375\n",
      "Best Model for Patient ID 277 with Params: {'hidden_size': 32, 'learning_rate': 0.005, 'num_epochs': 500}, MSE: 14.437499046325684\n",
      "Best Model for Patient ID 310 with Params: {'hidden_size': 64, 'learning_rate': 0.005, 'num_epochs': 1000}, MSE: 14.4375\n",
      "Best Model for Patient ID 320 with Params: {'hidden_size': 64, 'learning_rate': 0.005, 'num_epochs': 500}, MSE: 14.437499046325684\n",
      "Best Model for Patient ID 360 with Params: {'hidden_size': 32, 'learning_rate': 0.005, 'num_epochs': 500}, MSE: 14.437499046325684\n",
      "Best Model for Patient ID 395 with Params: {'hidden_size': 32, 'learning_rate': 0.001, 'num_epochs': 1000}, MSE: 14.4375\n",
      "Best Model for Patient ID 433 with Params: {'hidden_size': 64, 'learning_rate': 0.005, 'num_epochs': 500}, MSE: 14.437499046325684\n",
      "Best Model for Patient ID 445 with Params: {'hidden_size': 32, 'learning_rate': 0.005, 'num_epochs': 500}, MSE: 14.437499046325684\n",
      "Best Model for Patient ID 464 with Params: {'hidden_size': 64, 'learning_rate': 0.005, 'num_epochs': 500}, MSE: 14.437499046325684\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning configuration\n",
    "tuning_params = {\n",
    "    'hidden_size': [32, 64],\n",
    "    'learning_rate': [0.001, 0.005],\n",
    "    'num_epochs': [500, 1000]\n",
    "}\n",
    "\n",
    "# Initialize lists to store best models and corresponding MSEs\n",
    "best_models = []\n",
    "best_mse_per_patient = {}\n",
    "\n",
    "output_dir = \"Models\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "start_time = time.time()\n",
    "\n",
    "# For each patient, tune hyperparameters using the validation data\n",
    "for parent_id in val_df['parent_id'].unique():\n",
    "    print(f\"Tuning for Patient ID: {parent_id}\")\n",
    "    \n",
    "    # Get the data for the current patient (using validation data for both training and evaluation)\n",
    "    val_features, val_target = get_data_for_parent(train_df, parent_id)\n",
    "    \n",
    "    # Hyperparameter tuning for the current patient\n",
    "    best_mse = float('inf')\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    for hidden_size in tuning_params['hidden_size']:\n",
    "        for learning_rate in tuning_params['learning_rate']:\n",
    "            for num_epochs in tuning_params['num_epochs']:\n",
    "                print(f\"Training with hidden_size={hidden_size}, learning_rate={learning_rate}, num_epochs={num_epochs}...\")\n",
    "                \n",
    "                # Initialize model\n",
    "                model = SimpleRNN(input_size=val_features.shape[2], hidden_size=hidden_size, output_size=1)\n",
    "                optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "                criterion = nn.MSELoss()\n",
    "\n",
    "                # Training the model using validation data\n",
    "                model.train()\n",
    "                for epoch in range(num_epochs):\n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(val_features)\n",
    "                    loss = criterion(output, val_target)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # Evaluate on the validation set\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    val_predictions = model(val_features)\n",
    "                    val_mse = criterion(val_predictions, val_target).item()\n",
    "                    print(f\"Validation MSE for hidden_size={hidden_size}, learning_rate={learning_rate}, num_epochs={num_epochs}: {val_mse}\")\n",
    "\n",
    "                    # Track the best model for the current patient\n",
    "                    if val_mse < best_mse:\n",
    "                        best_mse = val_mse\n",
    "                        best_params = {'hidden_size': hidden_size, 'learning_rate': learning_rate, 'num_epochs': num_epochs}\n",
    "                        best_model = model\n",
    "\n",
    "    # Save the best model for the current patient\n",
    "    best_models.append((parent_id, best_model, best_params, best_mse))\n",
    "    best_mse_per_patient[parent_id] = best_mse\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Total training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# Output the best models and MSEs per patient\n",
    "for parent_id, model, params, mse in best_models:\n",
    "    print(f\"Best Model for Patient ID {parent_id} with Params: {params}, MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ff21eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 315.88746774535133\n"
     ]
    }
   ],
   "source": [
    "# Example: Evaluating on the test dataset\n",
    "def evaluate_rnn(models, test_df):\n",
    "    X_test = test_df.drop(columns=['parent_id', 'days_remaining'])\n",
    "    y_test = test_df['days_remaining']\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "    for i in range(len(X_test)):\n",
    "        test_sample = torch.tensor(X_test.iloc[i].values).float().unsqueeze(0).unsqueeze(0)\n",
    "        true_value = y_test.iloc[i]\n",
    "        prediction = ensemble_prediction(models, test_sample)\n",
    "        y_true.append(true_value)\n",
    "        y_pred.append(prediction)\n",
    "\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    return mse, y_true, y_pred\n",
    "\n",
    "# Evaluate the models on the test data\n",
    "mse, y_true, y_pred = evaluate_rnn([model for _, model, _, _ in best_models], test_df)\n",
    "print(f\"Test MSE: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bc02b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
