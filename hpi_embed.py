# -*- coding: utf-8 -*-
"""HPI embed

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DAj6AYxuWMZdKOU570c1W_EctvCI9UHf
"""

import numpy as np
import pandas as pd



embedding_path = "/content/cc_hpi_embed.txt"
embedding_dim = 100
word_vectors = {}

with open(embedding_path, "r", encoding="utf-8") as f:
    for line in f:
        parts = line.strip().split()
        if len(parts) != embedding_dim + 1:
            continue
        word = parts[0]
        vector = np.array(parts[1:], dtype=float)
        word_vectors[word] = vector


csv_path = "/content/drive/MyDrive/research/chief_complaint_cleaned_for_embed.csv"
df = pd.read_csv(csv_path)

complaint_col = "cleaned_complaint"

# vector averaging
def average_vector(text, word_vectors, embedding_dim=100):
    if pd.isna(text):  # handle missing values
        return np.zeros(embedding_dim)

    tokens = str(text).split()
    vectors = [word_vectors[word] for word in tokens if word in word_vectors]

    if vectors:
        return np.mean(vectors, axis=0)
    else:
        return np.zeros(embedding_dim)

df["embedding"] = df[complaint_col].apply(lambda x: average_vector(x, word_vectors))


embedding_df = pd.DataFrame(df["embedding"].to_list(), index=df.index)
embedding_df.columns = [f"cc_embedding_{i}" for i in range(embedding_dim)]

# combine
final_df = pd.concat([df.drop(columns=["embedding"]), embedding_df], axis=1)


final_df.to_csv("/content/drive/MyDrive/research/averaged_complaint_embeddings_cuml.csv", index=False)