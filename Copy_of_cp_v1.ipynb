{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Haimonti/CarePathways/blob/main/Copy_of_cp_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrnBDOO8SCty",
        "outputId": "4ea5157e-3b8c-4315-95fa-767bf3f5ac65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
            "Collecting dgl\n",
            "  Downloading dgl-1.1.2-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.7.22)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-1.1.2\n"
          ]
        }
      ],
      "source": [
        "pip install  dgl -f https://data.dgl.ai/wheels/repo.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pug_o26VIMoJ",
        "outputId": "7b077573-11b6-4259-d705-0ab70af877fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.3.0-py3-none-any.whl (404 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m404.2/404.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cmaes>=0.10.0 (from optuna)\n",
            "  Downloading cmaes-0.10.0-py3-none-any.whl (29 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.7.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n",
            "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna\n",
            "Successfully installed Mako-1.2.4 alembic-1.12.0 cmaes-0.10.0 colorlog-6.7.0 optuna-3.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install  dglgo -f https://data.dgl.ai/wheels-test/repo.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuUSapAfSkZS",
        "outputId": "40a54a6b-e986-4356-e5c6-b49117b55f82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels-test/repo.html\n",
            "Collecting dglgo\n",
            "  Downloading dglgo-0.0.2-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m522.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (0.9.0)\n",
            "Collecting isort>=5.10.1 (from dglgo)\n",
            "  Downloading isort-5.12.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autopep8>=1.6.0 (from dglgo)\n",
            "  Downloading autopep8-2.0.4-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpydoc>=1.1.0 (from dglgo)\n",
            "  Downloading numpydoc-1.5.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (2.3.0)\n",
            "Collecting ruamel.yaml>=0.17.20 (from dglgo)\n",
            "  Downloading ruamel.yaml-0.17.32-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from dglgo) (6.0.1)\n",
            "Collecting ogb>=1.3.3 (from dglgo)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rdkit-pypi (from dglgo)\n",
            "  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.2.2)\n",
            "Collecting pycodestyle>=2.10.0 (from autopep8>=1.6.0->dglgo)\n",
            "  Downloading pycodestyle-2.11.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: sphinx>=4.2 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (5.0.2)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (3.1.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (2.0.1+cu118)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.23.5)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (4.66.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (2.0.4)\n",
            "Collecting outdated>=0.2.0 (from ogb>=1.3.3->dglgo)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.0->dglgo) (0.5.0)\n",
            "Requirement already satisfied: pydantic-core==2.6.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.0->dglgo) (2.6.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.0->dglgo) (4.7.1)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.20->dglgo)\n",
            "  Downloading ruamel.yaml.clib-0.2.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (485 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (3.2.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.4.0->dglgo) (8.1.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi->dglgo) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.3)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb>=1.3.3->dglgo)\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2023.3.post1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.7)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.5)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.1.9)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.0.6)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.16.1)\n",
            "Requirement already satisfied: docutils<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.18.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (2.12.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (0.7.13)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sphinx>=4.2->numpydoc>=1.1.0->dglgo) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.12.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb>=1.3.3->dglgo) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->ogb>=1.3.3->dglgo) (16.0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb>=1.3.3->dglgo) (1.3.0)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7028 sha256=7f8e5999fcc6c79edd63f639a214af9d20d45d16576032c7af8c5bcae55afbf9\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, ruamel.yaml.clib, rdkit-pypi, pycodestyle, isort, ruamel.yaml, outdated, autopep8, ogb, numpydoc, dglgo\n",
            "Successfully installed autopep8-2.0.4 dglgo-0.0.2 isort-5.12.0 littleutils-0.2.2 numpydoc-1.5.0 ogb-1.3.6 outdated-0.2.2 pycodestyle-2.11.0 rdkit-pypi-2022.9.5 ruamel.yaml-0.17.32 ruamel.yaml.clib-0.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from optuna.trial import TrialState"
      ],
      "metadata": {
        "id": "xXuTdbVFIURp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "rZRxfuIkk5C1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/healthcare_gnn/someTest.csv\")\n",
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOTtSN15C0ys",
        "outputId": "9e72b60d-d3a8-4686-802a-7cc963d8e883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(145598, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
        "import dgl\n",
        "import dgl.data\n",
        "from dgl.data import DGLDataset\n",
        "from dgl.data import CSVDataset\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "class CarePathwaysDataset(DGLDataset):\n",
        "\n",
        "        def __init__(self):\n",
        "          super().__init__(name=\"care_pthways\")\n",
        "\n",
        "        def process(self):\n",
        "          nodes_data = pd.read_csv(\"/content/drive/MyDrive/healthcare_gnn/pt_pathways-v4.csv\")\n",
        "          print(nodes_data.shape)\n",
        "          #Attribute names\n",
        "          print(nodes_data.columns)\n",
        "          node_feat = nodes_data.drop(['id','Mean HLOS'], axis=1)\n",
        "          print(f\"Node Features Dimension {node_feat.shape}\")\n",
        "          tsr_feat = torch. tensor(node_feat.values)\n",
        "          torch.save(tsr_feat, 'data.pt')\n",
        "\n",
        "          edges_data = pd.read_csv(\"/content/drive/MyDrive/healthcare_gnn/someTest.csv\")\n",
        "          #node_features = torch.from_numpy(nodes_data[\"age\"].to_numpy())\n",
        "          node_features = tsr_feat\n",
        "          node_labels = torch.from_numpy(nodes_data[\"Mean HLOS\"].astype(float).to_numpy())\n",
        "          edge_features = torch.from_numpy(edges_data[\"Weight\"].to_numpy())\n",
        "          edges_src = torch.from_numpy(edges_data[\"Src\"].to_numpy())\n",
        "          edges_dst = torch.from_numpy(edges_data[\"Dst\"].to_numpy())\n",
        "\n",
        "          self.graph = dgl.graph((edges_src, edges_dst),num_nodes=nodes_data.shape[0])\n",
        "          self.graph.ndata[\"feat\"] = node_features\n",
        "          self.graph.ndata[\"label\"] = node_labels\n",
        "          self.graph.edata[\"weight\"] = edge_features\n",
        "\n",
        "           # If your dataset is a node classification dataset, you will need to assign\n",
        "          # masks indicating whether a node belongs to training, validation, and test set.\n",
        "          n_nodes = nodes_data.shape[0]\n",
        "          n_train = int(n_nodes * 0.6)\n",
        "          #train_inst = pd.read_csv(\"/content/drive/MyDrive/CarePathways/ptTrainInd.csv\")\n",
        "          n_val = int(n_nodes * 0.2)\n",
        "          #val_inst = pd.read_csv(\"/content/drive/MyDrive/CarePathways/ptValidInd.csv\")\n",
        "          n_test = 100\n",
        "          #test_inst = pd.read_csv(\"/content/drive/MyDrive/CarePathways/ptTestInd.csv\")\n",
        "          train_mask = torch.zeros(n_nodes, dtype=torch.int)\n",
        "          val_mask = torch.zeros(n_nodes, dtype=torch.int)\n",
        "          test_mask = torch.zeros(n_nodes, dtype=torch.int)\n",
        "          train_mask[:n_train] = int(1)\n",
        "          val_mask[n_train : n_train + n_val] = int(1)\n",
        "          test_mask[n_train + n_val :] = int(1)\n",
        "          self.graph.ndata[\"train_mask\"] = train_mask\n",
        "          self.graph.ndata[\"val_mask\"] = val_mask\n",
        "          self.graph.ndata[\"test_mask\"] = test_mask\n",
        "\n",
        "        def __getitem__(self, i):\n",
        "          return self.graph\n",
        "\n",
        "        def __len__(self):\n",
        "          return 1\n",
        "\n",
        "dataset = CarePathwaysDataset()\n",
        "g = dataset[0]\n",
        "print(g)\n",
        "\n",
        "# Gather statistics from the graph\n",
        "print(f\"Number of nodes {g.num_nodes}\")\n",
        "print(f\"Number of edges {g.num_edges}\")\n",
        "#print(f\"Average node degree {g.num_edges / g.num_nodes}\")\n",
        "#print(f\"Number of training nodes {train_mask.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgez3juQC8uB",
        "outputId": "9cf51139-66f0-4120-a7de-76d94dcaa165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "(508, 45)\n",
            "Index(['id', 'admission_disposition', 'age', 'sex', 'Hypertension',\n",
            "       'Chronic cardiac disease (not hypertension)', 'N/A', 'Diabetes',\n",
            "       'History of cancer [now in remission]', 'Other', 'Kidney disease',\n",
            "       'Obesity', 'Asthma', 'Rheumatologic disorder',\n",
            "       'Dementia [any etiology]', 'Chronic pulmonary (lung) disease',\n",
            "       'Pregnancy', 'Stroke', 'Cancer [active only]', 'Liver disease',\n",
            "       'Chronic renal', 'Chronic neurological disorder', 'Hematological',\n",
            "       'reason_for_admission_ARDS (adult respiratory distress syndrome) [J80]',\n",
            "       'reason_for_admission_Acquired respiratory distress syndrome [J80]',\n",
            "       'reason_for_admission_COVID-19 [U07.1]',\n",
            "       'reason_for_admission_COVID-19 determined by clinical diagnostic criteria [U07.2]',\n",
            "       'reason_for_admission_COVID-19 virus infection [U07.1]',\n",
            "       'reason_for_admission_COVID-19 with multiple comorbidities [U07.1]',\n",
            "       'reason_for_admission_Coronavirus infection [B34.2]',\n",
            "       'reason_for_admission_Cough [R05]',\n",
            "       'reason_for_admission_Febrile respiratory illness [J98.9, R50.9]',\n",
            "       'reason_for_admission_Fever of unknown origin [R50.9]',\n",
            "       'reason_for_admission_Hypoxemia [R09.0]',\n",
            "       'reason_for_admission_Hypoxia [R09.0]',\n",
            "       'reason_for_admission_Pneumonia [J18.9]',\n",
            "       'reason_for_admission_Pneumonia due to 2019-nCoV [U07.1, J12.8]',\n",
            "       'reason_for_admission_Pneumonia due to COVID-19 virus [U07.1, J12.8]',\n",
            "       'reason_for_admission_Respiratory distress [R06.0]',\n",
            "       'reason_for_admission_Respiratory failure [J96.99]',\n",
            "       'reason_for_admission_Respiratory tract infection [J98.8]',\n",
            "       'reason_for_admission_Shortness of breath [R06.0]',\n",
            "       'reason_for_admission_Shortness of breath with exposure to COVID-19 virus [R06.0, U07.2]',\n",
            "       'reason_for_admission_Suspected COVID-19 virus infection [U07.2]',\n",
            "       'Mean HLOS'],\n",
            "      dtype='object')\n",
            "Node Features Dimension (508, 43)\n",
            "Graph(num_nodes=508, num_edges=145598,\n",
            "      ndata_schemes={'feat': Scheme(shape=(43,), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.float64), 'train_mask': Scheme(shape=(), dtype=torch.int32), 'val_mask': Scheme(shape=(), dtype=torch.int32), 'test_mask': Scheme(shape=(), dtype=torch.int32)}\n",
            "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})\n",
            "Number of nodes <bound method DGLGraph.num_nodes of Graph(num_nodes=508, num_edges=145598,\n",
            "      ndata_schemes={'feat': Scheme(shape=(43,), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.float64), 'train_mask': Scheme(shape=(), dtype=torch.int32), 'val_mask': Scheme(shape=(), dtype=torch.int32), 'test_mask': Scheme(shape=(), dtype=torch.int32)}\n",
            "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})>\n",
            "Number of edges <bound method DGLGraph.num_edges of Graph(num_nodes=508, num_edges=145598,\n",
            "      ndata_schemes={'feat': Scheme(shape=(43,), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.float64), 'train_mask': Scheme(shape=(), dtype=torch.int32), 'val_mask': Scheme(shape=(), dtype=torch.int32), 'test_mask': Scheme(shape=(), dtype=torch.int32)}\n",
            "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nodes_data = pd.read_csv(\"/content/drive/MyDrive/healthcare_gnn/pt_pathways-v4_reg.csv\")\n",
        "nodes_data['Unnamed: 0']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvJn0KyylZk2",
        "outputId": "bba6b31b-e1ca-4512-dfe9-d4c6c5ca2625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        0\n",
              "1        1\n",
              "2        2\n",
              "3        3\n",
              "4        4\n",
              "      ... \n",
              "503    503\n",
              "504    504\n",
              "505    505\n",
              "506    506\n",
              "507    507\n",
              "Name: Unnamed: 0, Length: 508, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CarePathwaysDataset_reg(DGLDataset):\n",
        "\n",
        "        def __init__(self):\n",
        "          super().__init__(name=\"care_pthways\")\n",
        "\n",
        "        def process(self):\n",
        "          nodes_data = pd.read_csv(\"/content/drive/MyDrive/healthcare_gnn/pt_pathways-v4_reg.csv\")\n",
        "          print(nodes_data.shape)\n",
        "          #Attribute names\n",
        "          print(nodes_data.columns)\n",
        "          node_feat = nodes_data.drop(['id','Hospital LOS', 'Std Dev','Unnamed: 0','comorbidities_other','Mean HLOS'], axis=1) #LOS and std dev\n",
        "          print(f\"Node Features Dimension {node_feat.shape}\")\n",
        "          tsr_feat = torch. tensor(node_feat.values)\n",
        "          torch.save(tsr_feat, 'data.pt')\n",
        "\n",
        "          edges_data = pd.read_csv(\"/content/drive/MyDrive/healthcare_gnn/someTest.csv\")\n",
        "          #node_features = torch.from_numpy(nodes_data[\"age\"].to_numpy())\n",
        "          node_features = tsr_feat\n",
        "          node_labels = torch.from_numpy(nodes_data[\"Hospital LOS\"].astype(float).to_numpy()) #LOS\n",
        "          edge_features = torch.from_numpy(edges_data[\"Weight\"].to_numpy())\n",
        "          edges_src = torch.from_numpy(edges_data[\"Src\"].to_numpy())\n",
        "          edges_dst = torch.from_numpy(edges_data[\"Dst\"].to_numpy())\n",
        "\n",
        "          self.graph = dgl.graph((edges_src, edges_dst),num_nodes=nodes_data.shape[0])\n",
        "          self.graph.ndata[\"feat\"] = node_features\n",
        "          self.graph.ndata[\"label\"] = node_labels\n",
        "          self.graph.edata[\"weight\"] = edge_features\n",
        "\n",
        "           # If your dataset is a node classification dataset, you will need to assign\n",
        "          # masks indicating whether a node belongs to training, validation, and test set.\n",
        "          n_nodes = nodes_data.shape[0]\n",
        "          n_train = int(n_nodes * 0.6)\n",
        "          #train_inst = pd.read_csv(\"/content/drive/MyDrive/CarePathways/ptTrainInd.csv\")\n",
        "          n_val = int(n_nodes * 0.2)\n",
        "          #val_inst = pd.read_csv(\"/content/drive/MyDrive/CarePathways/ptValidInd.csv\")\n",
        "          n_test = 100\n",
        "          #test_inst = pd.read_csv(\"/content/drive/MyDrive/CarePathways/ptTestInd.csv\")\n",
        "\n",
        "          train_mask = torch.zeros(n_nodes, dtype=torch.int)\n",
        "          val_mask = torch.zeros(n_nodes, dtype=torch.int)\n",
        "          test_mask = torch.zeros(n_nodes, dtype=torch.int)\n",
        "          train_mask[:n_train] = int(1)\n",
        "          val_mask[n_train : n_train + n_val] = int(1)\n",
        "          test_mask[n_train + n_val :] = int(1)\n",
        "          self.graph.ndata[\"train_mask\"] = node_labels[:n_train]       #train_mask\n",
        "          self.graph.ndata[\"val_mask\"] =   node_labels[n_train : n_train + n_val]      #val_mask\n",
        "          self.graph.ndata[\"test_mask\"] =  node_labels[n_train + n_val :]    #test_mask\n",
        "\n",
        "        def __getitem__(self, i):\n",
        "          return self.graph\n",
        "\n",
        "        def __len__(self):\n",
        "          return 1\n",
        "dataset_reg = CarePathwaysDataset_reg()\n",
        "gg = dataset_reg[0]\n",
        "print(gg)\n",
        "\n",
        "# Gather statistics from the graph\n",
        "print(f\"Number of nodes {gg.num_nodes}\")\n",
        "print(f\"Number of edges {gg.num_edges}\")\n",
        "#print(f\"Average node degree {g.num_edges / g.num_nodes}\")\n",
        "#print(f\"Number of training nodes {train_mask.shape}\")"
      ],
      "metadata": {
        "id": "CcsbtLPZo5cK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67bd18aa-096c-4cbc-b761-65e38f79943a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(508, 55)\n",
            "Index(['Unnamed: 0', 'id', 'admission_disposition', 'age', 'sex',\n",
            "       'Hospital LOS', 'Std Dev', 'Hypertension',\n",
            "       'Chronic cardiac disease (not hypertension)', 'N/A', 'Diabetes',\n",
            "       'History of cancer [now in remission]', 'Other', 'Kidney disease',\n",
            "       'Obesity', 'Asthma', 'Rheumatologic disorder',\n",
            "       'Dementia [any etiology]', 'Chronic pulmonary (lung) disease',\n",
            "       'Pregnancy', 'Stroke', 'Cancer [active only]', 'Liver disease',\n",
            "       'Chronic renal', 'Chronic neurological disorder', 'Hematological',\n",
            "       'comorbidities_other', 'Mean HLOS',\n",
            "       'reason_for_admission_ARDS (adult respiratory distress syndrome) [J80]',\n",
            "       'reason_for_admission_Acquired respiratory distress syndrome [J80]',\n",
            "       'reason_for_admission_Atypical pneumonia [J18.9]',\n",
            "       'reason_for_admission_COVID-19 [U07.1]',\n",
            "       'reason_for_admission_COVID-19 determined by clinical diagnostic criteria [U07.2]',\n",
            "       'reason_for_admission_COVID-19 virus infection [U07.1]',\n",
            "       'reason_for_admission_COVID-19 with multiple comorbidities [U07.1]',\n",
            "       'reason_for_admission_Coronavirus infection [B34.2]',\n",
            "       'reason_for_admission_Cough [R05]',\n",
            "       'reason_for_admission_Febrile respiratory illness [J98.9, R50.9]',\n",
            "       'reason_for_admission_Fever [R50.9]',\n",
            "       'reason_for_admission_Fever of unknown origin [R50.9]',\n",
            "       'reason_for_admission_Hypoxemia [R09.0]',\n",
            "       'reason_for_admission_Hypoxia [R09.0]',\n",
            "       'reason_for_admission_Hypoxic [R09.0]',\n",
            "       'reason_for_admission_Myalgia [M79.19]',\n",
            "       'reason_for_admission_Pneumonia [J18.9]',\n",
            "       'reason_for_admission_Pneumonia due to 2019-nCoV [U07.1, J12.8]',\n",
            "       'reason_for_admission_Pneumonia due to COVID-19 virus [U07.1, J12.8]',\n",
            "       'reason_for_admission_Respiratory distress [R06.0]',\n",
            "       'reason_for_admission_Respiratory failure [J96.99]',\n",
            "       'reason_for_admission_Respiratory tract infection [J98.8]',\n",
            "       'reason_for_admission_Shortness of breath [R06.0]',\n",
            "       'reason_for_admission_Shortness of breath with exposure to COVID-19 virus [R06.0, U07.2]',\n",
            "       'reason_for_admission_Suspected COVID-19 virus infection [U07.2]',\n",
            "       'reason_for_admission_Tachypnea [R06.8]',\n",
            "       'reason_for_admission_Viral pneumonia [J12.9]'],\n",
            "      dtype='object')\n",
            "Node Features Dimension (508, 49)\n",
            "Graph(num_nodes=508, num_edges=145598,\n",
            "      ndata_schemes={'feat': Scheme(shape=(49,), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.float64), 'train_mask': Scheme(shape=(), dtype=torch.int32), 'val_mask': Scheme(shape=(), dtype=torch.int32), 'test_mask': Scheme(shape=(), dtype=torch.int32)}\n",
            "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})\n",
            "Number of nodes <bound method DGLGraph.num_nodes of Graph(num_nodes=508, num_edges=145598,\n",
            "      ndata_schemes={'feat': Scheme(shape=(49,), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.float64), 'train_mask': Scheme(shape=(), dtype=torch.int32), 'val_mask': Scheme(shape=(), dtype=torch.int32), 'test_mask': Scheme(shape=(), dtype=torch.int32)}\n",
            "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})>\n",
            "Number of edges <bound method DGLGraph.num_edges of Graph(num_nodes=508, num_edges=145598,\n",
            "      ndata_schemes={'feat': Scheme(shape=(49,), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.float64), 'train_mask': Scheme(shape=(), dtype=torch.int32), 'val_mask': Scheme(shape=(), dtype=torch.int32), 'test_mask': Scheme(shape=(), dtype=torch.int32)}\n",
            "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gg.ndata['label'][gg.ndata['test_mask']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEU-b-5MwAkf",
        "outputId": "ec5abe34-070a-43eb-f5f7-2aa65e92f652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,\n",
              "        21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21., 21.,  5.,\n",
              "         5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
              "         5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
              "         5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
              "         5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
              "         5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
              "         5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
              "         5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,  5.,\n",
              "         5.,  5.,  5.,  5.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training a Multilayer Perceptron (MLP)\n",
        "import torch\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self, hidden_channels):\n",
        "      super().__init__()\n",
        "      #torch.manual.seed(12113)\n",
        "      self.lin1 = Linear(43, hidden_channels)\n",
        "      self.lin2 = Linear(hidden_channels, 2)\n",
        "\n",
        "  def forward(self,x):\n",
        "      x = self.lin1(x)\n",
        "      #x = x.relu()\n",
        "      x = x.sigmoid()\n",
        "      x = self.lin2(x)\n",
        "      return x\n",
        "\n",
        "#train_data_sz = 422\n",
        "#modelMLP = MLP(train_data_sz, hidden_channels=16)\n",
        "#print(modelMLP)"
      ],
      "metadata": {
        "id": "vkzEEoW98F97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn import Linear\n",
        "\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#No GNNs involved -- simply run MLP on the data\n",
        "nodes_data = pd.read_csv(\"/content/drive/MyDrive/healthcare_gnn/pt_pathways-v4.csv\")\n",
        "#print(nodes_data.shape)\n",
        "#Attribute names\n",
        "#print(nodes_data.columns)\n",
        "node_feat = nodes_data.drop(['id','Mean HLOS'], axis=1)\n",
        "print(f\"Node features dimension: {node_feat.shape}\")\n",
        "tsr_feat = torch.tensor(node_feat.values)\n",
        "tsr_feat = tsr_feat.to(torch.float32)\n",
        "labels = torch.from_numpy(nodes_data[\"Mean HLOS\"].astype(float).to_numpy())\n",
        "\n",
        "#Split the data into train and test\n",
        "n_data_sz = nodes_data.shape[0]\n",
        "msk = np.random.rand(n_data_sz) < 0.8\n",
        "#print(f\"Mask {msk}\")\n",
        "nodes_data_train = tsr_feat[msk]\n",
        "print(f\"Size of training data {nodes_data_train.shape}\")\n",
        "nodes_data_test = tsr_feat[~msk]\n",
        "print(f\"Size of test data {nodes_data_test.shape}\")\n",
        "\n",
        "modelMLP = MLP(hidden_channels=16)\n",
        "print(f\"Model is: {modelMLP}\")\n",
        "#mdl = Linear(node_feat.shape[1], 2, bias=False)\n",
        "#Define loss criterion\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "#Define optimizer\n",
        "optimizer = torch.optim.Adam(modelMLP.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "def train():\n",
        "       optimizer.zero_grad()\n",
        "       #print(f\"Data type of model weight {mdl.weight.dtype}\")\n",
        "       #print(f\"Dimension of model weight - first {modelMLP.lin1.weight.shape}\")\n",
        "       #print(f\"Dimension of model weight - sec {modelMLP.lin2.weight.shape}\")\n",
        "       #print(f\"Data type of the features {nodes_data_train.dtype}\")\n",
        "       #out = mdl(nodes_data_train)\n",
        "       out = modelMLP(nodes_data_train)\n",
        "       #print(out.size())\n",
        "       #print(out.dtype)\n",
        "       #print(labels[msk].dtype)\n",
        "       #Check out the actual predictions\n",
        "       #print(f\"What is out? {out}\")\n",
        "\n",
        "       #Assume model is built on the entire dataset\n",
        "       loss = criterion(out,labels[msk].to(torch.long))\n",
        "       #print(f\"Loss is {loss}\")\n",
        "       #val_loss = criterion(out[\"val_mask\"],labels[\"val_mask\"])\n",
        "       loss.backward()\n",
        "       optimizer.step()\n",
        "       return loss\n",
        "\n",
        "def test():\n",
        "      #mdl.eval()\n",
        "      modelMLP.eval()\n",
        "      #outMLP = mdl(nodes_data_test)\n",
        "      outMLP = modelMLP(nodes_data_test)\n",
        "      pred = outMLP.argmax(dim=1)\n",
        "      test_correct = pred == labels[~msk]\n",
        "      test_acc = int(test_correct.sum()) / int(nodes_data_test.shape[0])\n",
        "      return test_acc\n",
        "\n",
        "for epoch in range (1, 10):\n",
        "     loss_tr = train()\n",
        "     test_acc = test()\n",
        "     print(f\"Epoch: {epoch: 1d}, Loss: {loss_tr: 0.4f}, Test Acc. {test_acc: 0.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hbh7WvVJCziR",
        "outputId": "4dae90c4-2b03-4222-a232-7e3e3b718032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Node features dimension: (508, 43)\n",
            "Size of training data torch.Size([394, 43])\n",
            "Size of test data torch.Size([114, 43])\n",
            "Model is: MLP(\n",
            "  (lin1): Linear(in_features=43, out_features=16, bias=True)\n",
            "  (lin2): Linear(in_features=16, out_features=2, bias=True)\n",
            ")\n",
            "Epoch:  1, Loss:  0.6238, Test Acc.  0.7105\n",
            "Epoch:  2, Loss:  0.6195, Test Acc.  0.7105\n",
            "Epoch:  3, Loss:  0.6189, Test Acc.  0.7105\n",
            "Epoch:  4, Loss:  0.6167, Test Acc.  0.7105\n",
            "Epoch:  5, Loss:  0.6136, Test Acc.  0.7105\n",
            "Epoch:  6, Loss:  0.6108, Test Acc.  0.7105\n",
            "Epoch:  7, Loss:  0.6086, Test Acc.  0.7105\n",
            "Epoch:  8, Loss:  0.6069, Test Acc.  0.7105\n",
            "Epoch:  9, Loss:  0.6052, Test Acc.  0.7105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dgl.nn import GraphConv\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, h_feats)\n",
        "        self.conv2 = GraphConv(h_feats, num_classes)\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h) #relu\n",
        "        h = self.conv2(g, h)\n",
        "        #m=nn.Linear(h.shape[1],h.shape[1]) #for regression\n",
        "        #h=m(h)\n",
        "        return h\n",
        "\n",
        "# Create the model with given dimensions\n",
        "print(g.ndata[\"feat\"].shape)\n",
        "model = GCN(g.ndata[\"feat\"].shape[1], 32, 2)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MNY5S6FJrH5",
        "outputId": "cf0e5b8e-7637-44e0-8b96-7d4fd28b191f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([508, 43])\n",
            "GCN(\n",
            "  (conv1): GraphConv(in=43, out=32, normalization=both, activation=None)\n",
            "  (conv2): GraphConv(in=32, out=2, normalization=both, activation=None)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(g, model):\n",
        "      #Select the Adam optimizer for no apparent reason\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "      best_val_acc = 0\n",
        "      best_test_acc = 0\n",
        "\n",
        "      features = g.ndata[\"feat\"]\n",
        "      print(f\"Features are: {features}\")\n",
        "      labels = g.ndata[\"label\"]\n",
        "      #print(f\"Labels are: {labels}\")\n",
        "      train_mask = g.ndata[\"train_mask\"]\n",
        "      #print(f\"Train_mask {train_mask}\")\n",
        "      val_mask = g.ndata[\"val_mask\"]\n",
        "      test_mask = g.ndata[\"test_mask\"]\n",
        "\n",
        "      for e in range(50):\n",
        "        # Forward\n",
        "        logits = model(g, features)\n",
        "        #print(f\"Prediction is {logits}\")\n",
        "        # Compute prediction\n",
        "        #logits=g.ndata[\"feat\"]\n",
        "        pred = logits.argmax(dim=1) #change it to = logits\n",
        "        #print(pred[train_mask])\n",
        "        #print(f\"Prediction is {pred}\")\n",
        "\n",
        "        # Compute loss\n",
        "        # Note that you should only compute the losses of the nodes in the training set.\n",
        "        #print(f\"Data type {logits[train_mask].dtype}\")\n",
        "        #print(f\"Data type {labels[train_mask].dtype}\")\n",
        "        loss = F.cross_entropy(logits[train_mask], labels[train_mask].to(torch.long))\n",
        "        #print(f\"Loss is {loss}\")\n",
        "\n",
        "        # Compute accuracy on training/validation/test #change it to mse\n",
        "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
        "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
        "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
        "\n",
        "        # Save the best validation accuracy and the corresponding test accuracy.\n",
        "        if best_val_acc < val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if e % 5 == 0:\n",
        "            print(\n",
        "                f\"In epoch {e}, loss: {loss:.3f}, val acc: {val_acc:.3f} (best {best_val_acc:.3f}), test acc: {test_acc:.3f} (best {best_test_acc:.3f})\"\n",
        "            )\n",
        "\n",
        "\n",
        "# Create the model with given dimensions\n",
        "model = GCN(43,10, 2)\n",
        "#print(model)\n",
        "train(g,model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyL061l6KDwa",
        "outputId": "34c78790-a0c8-45fd-bce7-ca1a4c8c4245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features are: tensor([[ 1, 74,  1,  ...,  0,  0,  0],\n",
            "        [ 1, 61,  0,  ...,  0,  0,  0],\n",
            "        [ 1, 58,  0,  ...,  0,  0,  0],\n",
            "        ...,\n",
            "        [ 1, 74,  1,  ...,  0,  0,  0],\n",
            "        [ 1, 48,  0,  ...,  0,  0,  0],\n",
            "        [ 1, 73,  1,  ...,  0,  0,  0]])\n",
            "In epoch 0, loss: 8.955, val acc: 0.199 (best 0.199), test acc: 0.203 (best 0.203)\n",
            "In epoch 5, loss: 2.393, val acc: 0.199 (best 0.199), test acc: 0.203 (best 0.203)\n",
            "In epoch 10, loss: 2.536, val acc: 0.801 (best 0.801), test acc: 0.797 (best 0.797)\n",
            "In epoch 15, loss: 0.722, val acc: 0.801 (best 0.801), test acc: 0.797 (best 0.797)\n",
            "In epoch 20, loss: 1.410, val acc: 0.199 (best 0.801), test acc: 0.203 (best 0.797)\n",
            "In epoch 25, loss: 0.672, val acc: 1.000 (best 1.000), test acc: 1.000 (best 1.000)\n",
            "In epoch 30, loss: 0.847, val acc: 0.801 (best 1.000), test acc: 0.797 (best 1.000)\n",
            "In epoch 35, loss: 0.805, val acc: 0.199 (best 1.000), test acc: 0.203 (best 1.000)\n",
            "In epoch 40, loss: 0.657, val acc: 0.199 (best 1.000), test acc: 0.203 (best 1.000)\n",
            "In epoch 45, loss: 0.682, val acc: 0.801 (best 1.000), test acc: 0.797 (best 1.000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#best_pred_array=[]\n",
        "def train_reg(g, model):\n",
        "      #Select the Adam optimizer for no apparent reaspon\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "      best_val_acc = np.inf\n",
        "      best_test_acc = np.inf\n",
        "      best_pred_array=[]\n",
        "\n",
        "      features = g.ndata[\"feat\"]\n",
        "      print(f\"Features are: {features}\")\n",
        "      labels = g.ndata[\"label\"]  #change it to length of stay\n",
        "\n",
        "      #print(f\"Labels are: {labels}\")\n",
        "      n_nodes = nodes_data.shape[0]\n",
        "      n_train = int(n_nodes * 0.6)\n",
        "      n_val = int(n_nodes * 0.2)\n",
        "      n_test = 100\n",
        "      train_mask = labels[:n_train]\n",
        "      #print(f\"Train_mask {train_mask}\")\n",
        "      val_mask = labels[n_train : n_train + n_val]\n",
        "      test_mask = labels[n_train + n_val :]\n",
        "\n",
        "      for e in range(50): #50\n",
        "        # Forward\n",
        "        logits = model(g, features)\n",
        "        #print(f\"Prediction is {logits}\")\n",
        "        # Compute prediction\n",
        "        #logits=g.ndata[\"feat\"]\n",
        "        pred = logits #logits.argmax(dim=1)\n",
        "        #print(pred[train_mask])\n",
        "        #print(f\"Prediction is {pred}\")\n",
        "\n",
        "        # Compute loss\n",
        "        # Note that you should only compute the losses of the nodes in the training set.\n",
        "        #print(f\"Data type {logits[train_mask].dtype}\")\n",
        "        #print(f\"Data type {labels[train_mask].dtype}\")\n",
        "\n",
        "        #loss = F.cross_entropy(logits[train_mask], labels[train_mask].to(torch.long))\n",
        "        logits=logits.flatten()\n",
        "        maeloss=torch.nn.L1Loss()\n",
        "        loss=maeloss(logits[:n_train], train_mask.to(torch.long))\n",
        "        #print(logits[train_mask])\n",
        "        #print(labels[train_mask])\n",
        "        #print(f\"Loss is {loss}\")\n",
        "\n",
        "        # Compute accuracy on training/validation/test\n",
        "        train_acc = ((pred[:n_train] - train_mask).float()**2).mean() #(pred[train_mask] == labels[train_mask]).float().mean()\n",
        "        val_acc = ((pred[n_train : n_train + n_val] - val_mask).float()**2).mean() #(pred[val_mask] == labels[val_mask]).float().mean()\n",
        "        test_acc = ((pred[n_train + n_val :] - test_mask).float()**2).mean() #(pred[test_mask] == labels[test_mask]).float().mean()\n",
        "\n",
        "        # Save the best validation accuracy and the corresponding test accuracy.\n",
        "        if best_val_acc > val_acc: #if the MSE is smaller\n",
        "            best_val_acc = val_acc\n",
        "            best_test_acc = test_acc\n",
        "            best_pred_array=pred[n_train + n_val :]\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if e % 5 == 0:\n",
        "            print(\n",
        "                f\"In epoch {e}, loss: {loss:.3f}, val acc: {val_acc:.3f} (best {best_val_acc:.3f}), test acc: {test_acc:.3f} (best {best_test_acc:.3f})\"\n",
        "            )\n",
        "      return best_pred_array\n",
        "\n",
        "\n",
        "# Create the model with given dimensions\n",
        "model_reg = GCN(gg.ndata[\"feat\"].shape[1],10, 1)\n",
        "#print(model)\n",
        "b=train_reg(gg,model_reg)"
      ],
      "metadata": {
        "id": "pkOsUA8IdJQ8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c07796a-e737-4578-d81f-72ce1dde36c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features are: tensor([[ 1, 74,  1,  ...,  0,  0,  0],\n",
            "        [ 1, 61,  0,  ...,  0,  0,  0],\n",
            "        [ 1, 58,  0,  ...,  0,  0,  0],\n",
            "        ...,\n",
            "        [ 1, 74,  1,  ...,  0,  0,  0],\n",
            "        [ 1, 48,  0,  ...,  0,  0,  0],\n",
            "        [ 1, 73,  1,  ...,  0,  0,  0]])\n",
            "In epoch 0, loss: 9.059, val acc: 260.779 (best 260.779), test acc: 124.294 (best 124.294)\n",
            "In epoch 5, loss: 7.585, val acc: 176.503 (best 176.503), test acc: 82.736 (best 82.736)\n",
            "In epoch 10, loss: 7.787, val acc: 167.762 (best 166.793), test acc: 83.197 (best 83.503)\n",
            "In epoch 15, loss: 7.522, val acc: 183.538 (best 166.793), test acc: 84.051 (best 83.503)\n",
            "In epoch 20, loss: 7.604, val acc: 197.733 (best 166.793), test acc: 88.910 (best 83.503)\n",
            "In epoch 25, loss: 7.532, val acc: 189.346 (best 166.793), test acc: 85.764 (best 83.503)\n",
            "In epoch 30, loss: 7.549, val acc: 179.753 (best 166.793), test acc: 83.223 (best 83.503)\n",
            "In epoch 35, loss: 7.521, val acc: 183.657 (best 166.793), test acc: 84.087 (best 83.503)\n",
            "In epoch 40, loss: 7.531, val acc: 189.295 (best 166.793), test acc: 85.752 (best 83.503)\n",
            "In epoch 45, loss: 7.518, val acc: 184.847 (best 166.793), test acc: 84.406 (best 83.503)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(gg.ndata['label'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJiXaLOQqYHh",
        "outputId": "a480a4dd-5a58-4554-ffb0-04a2e987fde9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "508"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b.flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNEKeI2M4qu7",
        "outputId": "d61a91d4-5251-44c1-c4ce-60a0f5e2dc5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10.6490, 11.1356, 12.6123, 13.6021, 13.0533, 11.1356,  5.5421, 14.9048,\n",
              "        10.3443, 14.0721,  9.6797, 11.0858, 13.8120, 14.2992, 14.9020, 13.8722,\n",
              "         7.1134, 14.9020, 14.7286, 14.0721, 14.2992, 12.6123, 11.1356, 10.6490,\n",
              "        13.3184, 14.7191, 11.9227, 13.9637, 14.5996, 14.9048, 14.0721, 15.1905,\n",
              "        12.3659, 13.6021, 11.8768, 12.4450, 12.8042, 15.0928, 12.8042, 14.7286,\n",
              "        14.9020, 14.2992, 14.5996, 11.0858, 14.6867, 14.7219, 10.6490, 11.2912,\n",
              "        14.5996, 14.7286, 14.7192, 12.9109, 14.5996, 12.4450, 14.9020,  7.3560,\n",
              "        14.7191, 14.9048, 15.1201, 14.7219, 13.3184, 15.1201, 15.1801, 11.1356,\n",
              "        14.5990, 14.7191, 13.0532, 13.5653, 15.1201, 14.5996, 10.7089, 12.6123,\n",
              "         3.6736, 15.1588, 11.1356, 13.5653, 14.6037, 13.5653, 14.0721, 12.9109,\n",
              "        14.6354, 13.1444,  6.3876, 14.7481, 14.2992, 14.7286, 14.9048, 13.3184,\n",
              "         9.3715, 15.1801, 13.3184, 11.0858, 15.1801, 13.9637, 14.9020, 12.6123,\n",
              "        14.6354, 12.4272, 15.1801, 14.5760, 15.1801, 10.6152, 15.0928],\n",
              "       grad_fn=<ReshapeAliasBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gg.ndata['label'][405:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2I17KuN3rvR",
        "outputId": "ce902545-13a7-410b-9c34-7743ea753f9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([28.,  6., 10.,  1.,  9., 13.,  8.,  7., 13., 44.,  4.,  5.,  4.,  9.,\n",
              "        17., 14.,  7., 28., 17.,  9.,  5., 30.,  8.,  8.,  2.,  5.,  5., 32.,\n",
              "         4., 24.,  3.,  8., 10.,  4.,  3., 13.,  3., 10., 27.,  8.,  2.,  9.,\n",
              "        39., 11., 25.,  3.,  8., 10., 34., 14., 31.,  4., 10.,  7.,  6.,  3.,\n",
              "         5.,  9.,  6.,  4.,  6.,  6.,  6., 10., 36.,  3.,  6.,  4.,  4., 26.,\n",
              "         7.,  4.,  3.,  7., 10.,  8., 11.,  5., 14.,  7.,  8.,  8.,  7.,  7.,\n",
              "         9., 12., 21.,  4.,  3.,  9.,  5., 10., 12., 18., 11.,  2.,  4.,  2.,\n",
              "        13., 19.,  9.,  7.,  5.], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "iCLsky024akl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(gg.ndata['label'][405:].detach().numpy(), b.flatten().detach().numpy())\n",
        "plt.ylabel(\"pred\")\n",
        "plt.xlabel(\"actual\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "tuzGxzVj5STn",
        "outputId": "f8b96662-337b-4f75-dc3f-049305f68ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(gg.ndata['label'][405:].detach().numpy(),gg.ndata['label'][405:].detach().numpy()- b.flatten().detach().numpy())\n",
        "plt.ylabel(\"residual\")\n",
        "plt.xlabel(\"actual\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "8r09zbgmSbTm",
        "outputId": "c2d68c5c-1cde-4f86-c793-b71527cf103d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set up the regression model\n",
        "#difference between hop and neighbors\n",
        "def objective(trial):\n",
        "\n",
        "\n",
        "\n",
        "  num_layers=trial.suggest_int(\"num_layer\", 1,3)\n",
        "  hidden_size=trial.suggest_int(\"hidden_size\",16,512)\n",
        "  dropout=trial.suggest_uniform(\"dropout\",0.1,0.5)\n",
        "  lr=trial.suggest_loguniform(\"learning_rate\",1e-5,5e-1)\n",
        "  optimizer_name=trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "  best_val_acc = 0\n",
        "  best_test_acc = 0\n",
        "  optimizer = getattr(torch.optim, optimizer_name)(model.parameters(), lr=lr)\n",
        "  features = g.ndata[\"feat\"]\n",
        "  labels = g.ndata[\"label\"]\n",
        "      #print(f\"Labels are: {labels}\")\n",
        "  train_mask = g.ndata[\"train_mask\"]\n",
        "      #print(f\"Train_mask {train_mask}\")\n",
        "  val_mask = g.ndata[\"val_mask\"]\n",
        "  test_mask = g.ndata[\"test_mask\"]\n",
        "  for e in range(50):\n",
        "        # Forward\n",
        "        logits = model(g, features)\n",
        "        #print(f\"Prediction is {logits}\")\n",
        "        # Compute prediction\n",
        "        #logits=g.ndata[\"feat\"]\n",
        "        pred = logits.argmax(dim=1)\n",
        "        #print(pred[train_mask])\n",
        "        #print(f\"Prediction is {pred}\")\n",
        "\n",
        "        # Compute loss\n",
        "        # Note that you should only compute the losses of the nodes in the training set.\n",
        "        #print(f\"Data type {logits[train_mask].dtype}\")\n",
        "        #print(f\"Data type {labels[train_mask].dtype}\")\n",
        "        loss = F.cross_entropy(logits[train_mask], labels[train_mask].to(torch.long))\n",
        "        #print(f\"Loss is {loss}\")\n",
        "\n",
        "        # Compute accuracy on training/validation/test\n",
        "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
        "        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
        "        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
        "        trial.report(test_acc, e)\n",
        "        if trial.should_prune():\n",
        "          raise optuna.exceptions.TrialPruned()\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=100, timeout=600)\n",
        "\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))\n",
        "model = GCN(43,10, 2)\n",
        "#print(model)\n",
        "objective(g,model)"
      ],
      "metadata": {
        "id": "hJUK2_cSPxFr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "outputId": "20397717-0e82-4a0f-c253-79535589e8c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2023-09-01 06:00:20,181] A new study created in memory with name: no-name-5f925152-c991-421c-9015-540fe9cf647b\n",
            "[W 2023-09-01 06:00:20,187] Trial 0 failed with parameters: {} because of the following error: TypeError(\"objective() missing 2 required positional arguments: 'model' and 'trial'\").\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "TypeError: objective() missing 2 required positional arguments: 'model' and 'trial'\n",
            "[W 2023-09-01 06:00:20,190] Trial 0 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-af81de79ee6b>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0;32mraise\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mpruned_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRUNED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \"\"\"\n\u001b[0;32m--> 442\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    443\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     ):\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: objective() missing 2 required positional arguments: 'model' and 'trial'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "param={\n",
        "    \"num_layers\":trial.suggest_int(\"num_layer\", 1,3),\n",
        "      \"hidden_size\": trial.suggest_int(\"hidden_size\",16,512),\n",
        "      \"dropout\": trial.suggest_uniform(\"dropout\",0.1,0.5),\n",
        "      \"learning_rate\": trial.suggest_loguniform(\"learning_rate\",1e-5,5e-1),\n",
        "      \"optimizer_name\" : trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
        "}"
      ],
      "metadata": {
        "id": "dSfMBhg7NVnW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}